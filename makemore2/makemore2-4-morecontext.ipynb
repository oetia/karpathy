{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = open(\"data/names.txt\").read()\n",
    "names = raw.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(\"\".join(names) + \".\")))\n",
    "char_to_num = { char: num for num, char in enumerate(chars) }\n",
    "num_to_char = { num: char for char, num in char_to_num.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 4, 27]), torch.Size([228146, 27]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "Y = []; y_idx = []\n",
    "eye = torch.eye(len(chars))\n",
    "\n",
    "context_window = 4\n",
    "for name in names:\n",
    "  string = \".\" * (context_window) + name + \".\"\n",
    "  string_nums = [char_to_num[char] for char in string]\n",
    "\n",
    "  for idx in range(context_window, len(string)):\n",
    "    substring_nums = string_nums[idx - context_window:idx]\n",
    "    target_num = string_nums[idx]\n",
    "    x = eye[substring_nums]; X.append(x)\n",
    "    y = eye[target_num]; Y.append(y); y_idx.append(target_num)\n",
    "    \n",
    "    # print(f\"{string[idx - context_window:idx]} -> {string[idx]}\")\n",
    "    # print(f\"{substring_nums} -> {target_num}\")\n",
    "    # print(x, y)\n",
    "\n",
    "X = torch.stack(X) # stack to merge list of tensors\n",
    "Y = torch.stack(Y); y_idx = torch.tensor(y_idx)\n",
    "\n",
    "X.shape, Y.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing parameters\n",
    "generator = torch.Generator().manual_seed(14)\n",
    "embedding_vector_dimensionality = 2\n",
    "embedding_matrix = torch.randn((len(chars), embedding_vector_dimensionality), generator=generator, requires_grad=True)\n",
    "\n",
    "hidden_layer_num_neurons = 100\n",
    "hidden_layer_weights = torch.randn((context_window * embedding_vector_dimensionality, hidden_layer_num_neurons), generator=generator, requires_grad=True)\n",
    "hidden_layer_biases = torch.randn((hidden_layer_num_neurons), generator=generator, requires_grad=True)\n",
    "\n",
    "output_layer_num_neurons = len(chars)\n",
    "output_layer_weights = torch.randn((hidden_layer_num_neurons, output_layer_num_neurons), generator=generator, requires_grad=True)\n",
    "output_layer_biases = torch.randn((output_layer_num_neurons), generator=generator, requires_grad=True)\n",
    "\n",
    "parameters = [embedding_matrix, hidden_layer_weights, hidden_layer_biases, output_layer_weights, output_layer_biases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228146, 4, 2])\n",
      "torch.Size([228146, 8])\n",
      "torch.Size([228146, 100])\n",
      "torch.Size([228146, 27])\n",
      "torch.Size([228146, 27]) tensor(True)\n",
      "torch.Size([228146])\n",
      "tensor(16.2682, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "embeddings = X @ embedding_matrix\n",
    "print(embeddings.shape)\n",
    "\n",
    "embeddings_flattened = embeddings.view(-1, context_window * embedding_vector_dimensionality) # think about traversal order\n",
    "print(embeddings_flattened.shape)\n",
    "\n",
    "hidden_layer_preactivations = embeddings_flattened @ hidden_layer_weights + hidden_layer_biases\n",
    "# hidden_layer_activations = torch.maximum(hidden_layer_preactivations, torch.tensor(0.0))\n",
    "hidden_layer_activations = hidden_layer_preactivations.tanh()\n",
    "print(hidden_layer_activations.shape)\n",
    "\n",
    "output_layer_preactivations = hidden_layer_activations @ output_layer_weights + output_layer_biases\n",
    "output_layer_activations = output_layer_preactivations\n",
    "logits = output_layer_activations\n",
    "print(logits.shape)\n",
    "\n",
    "logits_sub_max = logits - logits.max(dim=1, keepdim=True).values\n",
    "counts = logits_sub_max.exp()\n",
    "prob_distributions = counts / counts.sum(dim=1, keepdim=True)\n",
    "print(prob_distributions.shape, prob_distributions.sum(dim=1).isclose(torch.tensor(1.0)).all())\n",
    "\n",
    "target_probs = prob_distributions[torch.arange(X.shape[0]), y_idx]\n",
    "target_logprobs = target_probs.log()\n",
    "print(target_logprobs.shape)\n",
    "\n",
    "negative_average_log_likelihood = -target_logprobs.mean()\n",
    "loss = negative_average_log_likelihood\n",
    "print(loss)\n",
    "\n",
    "intermediates = [embeddings, embeddings_flattened, hidden_layer_preactivations, hidden_layer_activations, output_layer_preactivations, output_layer_activations, logits, logits_sub_max, counts, prob_distributions, target_probs, target_logprobs]\n",
    "params_and_intermediates = parameters + intermediates\n",
    "\n",
    "# tensor(15.7477, grad_fn=<NegBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "for tensor in params_and_intermediates:\n",
    "  tensor.grad = None\n",
    "\n",
    "learning_rate = 0.01\n",
    "loss.backward()\n",
    "embedding_matrix.data = embedding_matrix.data - learning_rate * embedding_matrix.grad\n",
    "hidden_layer_weights.data = hidden_layer_weights.data - learning_rate * hidden_layer_weights.grad\n",
    "hidden_layer_biases.data = hidden_layer_biases.data - learning_rate * hidden_layer_biases.grad\n",
    "output_layer_weights.data = output_layer_weights.data - learning_rate * output_layer_weights.grad\n",
    "output_layer_biases.data = output_layer_biases.data - learning_rate * output_layer_biases.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computation graph gets nuked after backward() called. don't need to worry about duplicate nodes getting created each forward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(16.2055, grad_fn=<NegBackward0>)\n",
      "1 tensor(15.5977, grad_fn=<NegBackward0>)\n",
      "2 tensor(15.0310, grad_fn=<NegBackward0>)\n",
      "3 tensor(14.4924, grad_fn=<NegBackward0>)\n",
      "4 tensor(13.9861, grad_fn=<NegBackward0>)\n",
      "5 tensor(13.4927, grad_fn=<NegBackward0>)\n",
      "6 tensor(12.9937, grad_fn=<NegBackward0>)\n",
      "7 tensor(12.4881, grad_fn=<NegBackward0>)\n",
      "8 tensor(11.9912, grad_fn=<NegBackward0>)\n",
      "9 tensor(11.5278, grad_fn=<NegBackward0>)\n",
      "10 tensor(11.1313, grad_fn=<NegBackward0>)\n",
      "11 tensor(10.8109, grad_fn=<NegBackward0>)\n",
      "12 tensor(10.5232, grad_fn=<NegBackward0>)\n",
      "13 tensor(10.2513, grad_fn=<NegBackward0>)\n",
      "14 tensor(9.9924, grad_fn=<NegBackward0>)\n",
      "15 tensor(9.7453, grad_fn=<NegBackward0>)\n",
      "16 tensor(9.5090, grad_fn=<NegBackward0>)\n",
      "17 tensor(9.2829, grad_fn=<NegBackward0>)\n",
      "18 tensor(9.0667, grad_fn=<NegBackward0>)\n",
      "19 tensor(8.8600, grad_fn=<NegBackward0>)\n",
      "20 tensor(8.6631, grad_fn=<NegBackward0>)\n",
      "21 tensor(8.4759, grad_fn=<NegBackward0>)\n",
      "22 tensor(8.2997, grad_fn=<NegBackward0>)\n",
      "23 tensor(8.1341, grad_fn=<NegBackward0>)\n",
      "24 tensor(7.9823, grad_fn=<NegBackward0>)\n",
      "25 tensor(7.8372, grad_fn=<NegBackward0>)\n",
      "26 tensor(7.7085, grad_fn=<NegBackward0>)\n",
      "27 tensor(7.5676, grad_fn=<NegBackward0>)\n",
      "28 tensor(7.4469, grad_fn=<NegBackward0>)\n",
      "29 tensor(7.3041, grad_fn=<NegBackward0>)\n",
      "30 tensor(7.1846, grad_fn=<NegBackward0>)\n",
      "31 tensor(7.0532, grad_fn=<NegBackward0>)\n",
      "32 tensor(6.9383, grad_fn=<NegBackward0>)\n",
      "33 tensor(6.8202, grad_fn=<NegBackward0>)\n",
      "34 tensor(6.7116, grad_fn=<NegBackward0>)\n",
      "35 tensor(6.6037, grad_fn=<NegBackward0>)\n",
      "36 tensor(6.5016, grad_fn=<NegBackward0>)\n",
      "37 tensor(6.4013, grad_fn=<NegBackward0>)\n",
      "38 tensor(6.3050, grad_fn=<NegBackward0>)\n",
      "39 tensor(6.2108, grad_fn=<NegBackward0>)\n",
      "40 tensor(6.1197, grad_fn=<NegBackward0>)\n",
      "41 tensor(6.0308, grad_fn=<NegBackward0>)\n",
      "42 tensor(5.9443, grad_fn=<NegBackward0>)\n",
      "43 tensor(5.8600, grad_fn=<NegBackward0>)\n",
      "44 tensor(5.7780, grad_fn=<NegBackward0>)\n",
      "45 tensor(5.6979, grad_fn=<NegBackward0>)\n",
      "46 tensor(5.6199, grad_fn=<NegBackward0>)\n",
      "47 tensor(5.5438, grad_fn=<NegBackward0>)\n",
      "48 tensor(5.4697, grad_fn=<NegBackward0>)\n",
      "49 tensor(5.3974, grad_fn=<NegBackward0>)\n",
      "50 tensor(5.3271, grad_fn=<NegBackward0>)\n",
      "51 tensor(5.2585, grad_fn=<NegBackward0>)\n",
      "52 tensor(5.1918, grad_fn=<NegBackward0>)\n",
      "53 tensor(5.1270, grad_fn=<NegBackward0>)\n",
      "54 tensor(5.0641, grad_fn=<NegBackward0>)\n",
      "55 tensor(5.0030, grad_fn=<NegBackward0>)\n",
      "56 tensor(4.9438, grad_fn=<NegBackward0>)\n",
      "57 tensor(4.8866, grad_fn=<NegBackward0>)\n",
      "58 tensor(4.8312, grad_fn=<NegBackward0>)\n",
      "59 tensor(4.7778, grad_fn=<NegBackward0>)\n",
      "60 tensor(4.7262, grad_fn=<NegBackward0>)\n",
      "61 tensor(4.6764, grad_fn=<NegBackward0>)\n",
      "62 tensor(4.6284, grad_fn=<NegBackward0>)\n",
      "63 tensor(4.5822, grad_fn=<NegBackward0>)\n",
      "64 tensor(4.5375, grad_fn=<NegBackward0>)\n",
      "65 tensor(4.4943, grad_fn=<NegBackward0>)\n",
      "66 tensor(4.4526, grad_fn=<NegBackward0>)\n",
      "67 tensor(4.4122, grad_fn=<NegBackward0>)\n",
      "68 tensor(4.3731, grad_fn=<NegBackward0>)\n",
      "69 tensor(4.3352, grad_fn=<NegBackward0>)\n",
      "70 tensor(4.2983, grad_fn=<NegBackward0>)\n",
      "71 tensor(4.2626, grad_fn=<NegBackward0>)\n",
      "72 tensor(4.2278, grad_fn=<NegBackward0>)\n",
      "73 tensor(4.1940, grad_fn=<NegBackward0>)\n",
      "74 tensor(4.1610, grad_fn=<NegBackward0>)\n",
      "75 tensor(4.1290, grad_fn=<NegBackward0>)\n",
      "76 tensor(4.0976, grad_fn=<NegBackward0>)\n",
      "77 tensor(4.0672, grad_fn=<NegBackward0>)\n",
      "78 tensor(4.0373, grad_fn=<NegBackward0>)\n",
      "79 tensor(4.0083, grad_fn=<NegBackward0>)\n",
      "80 tensor(3.9798, grad_fn=<NegBackward0>)\n",
      "81 tensor(3.9521, grad_fn=<NegBackward0>)\n",
      "82 tensor(3.9249, grad_fn=<NegBackward0>)\n",
      "83 tensor(3.8984, grad_fn=<NegBackward0>)\n",
      "84 tensor(3.8723, grad_fn=<NegBackward0>)\n",
      "85 tensor(3.8470, grad_fn=<NegBackward0>)\n",
      "86 tensor(3.8220, grad_fn=<NegBackward0>)\n",
      "87 tensor(3.7976, grad_fn=<NegBackward0>)\n",
      "88 tensor(3.7736, grad_fn=<NegBackward0>)\n",
      "89 tensor(3.7502, grad_fn=<NegBackward0>)\n",
      "90 tensor(3.7270, grad_fn=<NegBackward0>)\n",
      "91 tensor(3.7044, grad_fn=<NegBackward0>)\n",
      "92 tensor(3.6820, grad_fn=<NegBackward0>)\n",
      "93 tensor(3.6603, grad_fn=<NegBackward0>)\n",
      "94 tensor(3.6386, grad_fn=<NegBackward0>)\n",
      "95 tensor(3.6175, grad_fn=<NegBackward0>)\n",
      "96 tensor(3.5965, grad_fn=<NegBackward0>)\n",
      "97 tensor(3.5760, grad_fn=<NegBackward0>)\n",
      "98 tensor(3.5556, grad_fn=<NegBackward0>)\n",
      "99 tensor(3.5358, grad_fn=<NegBackward0>)\n",
      "100 tensor(3.5158, grad_fn=<NegBackward0>)\n",
      "101 tensor(3.4967, grad_fn=<NegBackward0>)\n",
      "102 tensor(3.4773, grad_fn=<NegBackward0>)\n",
      "103 tensor(3.4588, grad_fn=<NegBackward0>)\n",
      "104 tensor(3.4400, grad_fn=<NegBackward0>)\n",
      "105 tensor(3.4223, grad_fn=<NegBackward0>)\n",
      "106 tensor(3.4041, grad_fn=<NegBackward0>)\n",
      "107 tensor(3.3872, grad_fn=<NegBackward0>)\n",
      "108 tensor(3.3696, grad_fn=<NegBackward0>)\n",
      "109 tensor(3.3537, grad_fn=<NegBackward0>)\n",
      "110 tensor(3.3368, grad_fn=<NegBackward0>)\n",
      "111 tensor(3.3218, grad_fn=<NegBackward0>)\n",
      "112 tensor(3.3056, grad_fn=<NegBackward0>)\n",
      "113 tensor(3.2917, grad_fn=<NegBackward0>)\n",
      "114 tensor(3.2761, grad_fn=<NegBackward0>)\n",
      "115 tensor(3.2633, grad_fn=<NegBackward0>)\n",
      "116 tensor(3.2483, grad_fn=<NegBackward0>)\n",
      "117 tensor(3.2366, grad_fn=<NegBackward0>)\n",
      "118 tensor(3.2222, grad_fn=<NegBackward0>)\n",
      "119 tensor(3.2117, grad_fn=<NegBackward0>)\n",
      "120 tensor(3.1977, grad_fn=<NegBackward0>)\n",
      "121 tensor(3.1882, grad_fn=<NegBackward0>)\n",
      "122 tensor(3.1748, grad_fn=<NegBackward0>)\n",
      "123 tensor(3.1664, grad_fn=<NegBackward0>)\n",
      "124 tensor(3.1535, grad_fn=<NegBackward0>)\n",
      "125 tensor(3.1459, grad_fn=<NegBackward0>)\n",
      "126 tensor(3.1336, grad_fn=<NegBackward0>)\n",
      "127 tensor(3.1269, grad_fn=<NegBackward0>)\n",
      "128 tensor(3.1151, grad_fn=<NegBackward0>)\n",
      "129 tensor(3.1091, grad_fn=<NegBackward0>)\n",
      "130 tensor(3.0980, grad_fn=<NegBackward0>)\n",
      "131 tensor(3.0926, grad_fn=<NegBackward0>)\n",
      "132 tensor(3.0820, grad_fn=<NegBackward0>)\n",
      "133 tensor(3.0772, grad_fn=<NegBackward0>)\n",
      "134 tensor(3.0672, grad_fn=<NegBackward0>)\n",
      "135 tensor(3.0628, grad_fn=<NegBackward0>)\n",
      "136 tensor(3.0533, grad_fn=<NegBackward0>)\n",
      "137 tensor(3.0493, grad_fn=<NegBackward0>)\n",
      "138 tensor(3.0403, grad_fn=<NegBackward0>)\n",
      "139 tensor(3.0367, grad_fn=<NegBackward0>)\n",
      "140 tensor(3.0280, grad_fn=<NegBackward0>)\n",
      "141 tensor(3.0248, grad_fn=<NegBackward0>)\n",
      "142 tensor(3.0165, grad_fn=<NegBackward0>)\n",
      "143 tensor(3.0135, grad_fn=<NegBackward0>)\n",
      "144 tensor(3.0055, grad_fn=<NegBackward0>)\n",
      "145 tensor(3.0028, grad_fn=<NegBackward0>)\n",
      "146 tensor(2.9951, grad_fn=<NegBackward0>)\n",
      "147 tensor(2.9926, grad_fn=<NegBackward0>)\n",
      "148 tensor(2.9852, grad_fn=<NegBackward0>)\n",
      "149 tensor(2.9828, grad_fn=<NegBackward0>)\n",
      "150 tensor(2.9757, grad_fn=<NegBackward0>)\n",
      "151 tensor(2.9735, grad_fn=<NegBackward0>)\n",
      "152 tensor(2.9666, grad_fn=<NegBackward0>)\n",
      "153 tensor(2.9646, grad_fn=<NegBackward0>)\n",
      "154 tensor(2.9579, grad_fn=<NegBackward0>)\n",
      "155 tensor(2.9560, grad_fn=<NegBackward0>)\n",
      "156 tensor(2.9495, grad_fn=<NegBackward0>)\n",
      "157 tensor(2.9477, grad_fn=<NegBackward0>)\n",
      "158 tensor(2.9415, grad_fn=<NegBackward0>)\n",
      "159 tensor(2.9397, grad_fn=<NegBackward0>)\n",
      "160 tensor(2.9337, grad_fn=<NegBackward0>)\n",
      "161 tensor(2.9321, grad_fn=<NegBackward0>)\n",
      "162 tensor(2.9263, grad_fn=<NegBackward0>)\n",
      "163 tensor(2.9247, grad_fn=<NegBackward0>)\n",
      "164 tensor(2.9191, grad_fn=<NegBackward0>)\n",
      "165 tensor(2.9176, grad_fn=<NegBackward0>)\n",
      "166 tensor(2.9121, grad_fn=<NegBackward0>)\n",
      "167 tensor(2.9107, grad_fn=<NegBackward0>)\n",
      "168 tensor(2.9054, grad_fn=<NegBackward0>)\n",
      "169 tensor(2.9041, grad_fn=<NegBackward0>)\n",
      "170 tensor(2.8990, grad_fn=<NegBackward0>)\n",
      "171 tensor(2.8977, grad_fn=<NegBackward0>)\n",
      "172 tensor(2.8927, grad_fn=<NegBackward0>)\n",
      "173 tensor(2.8915, grad_fn=<NegBackward0>)\n",
      "174 tensor(2.8867, grad_fn=<NegBackward0>)\n",
      "175 tensor(2.8855, grad_fn=<NegBackward0>)\n",
      "176 tensor(2.8809, grad_fn=<NegBackward0>)\n",
      "177 tensor(2.8797, grad_fn=<NegBackward0>)\n",
      "178 tensor(2.8753, grad_fn=<NegBackward0>)\n",
      "179 tensor(2.8741, grad_fn=<NegBackward0>)\n",
      "180 tensor(2.8698, grad_fn=<NegBackward0>)\n",
      "181 tensor(2.8687, grad_fn=<NegBackward0>)\n",
      "182 tensor(2.8646, grad_fn=<NegBackward0>)\n",
      "183 tensor(2.8635, grad_fn=<NegBackward0>)\n",
      "184 tensor(2.8595, grad_fn=<NegBackward0>)\n",
      "185 tensor(2.8585, grad_fn=<NegBackward0>)\n",
      "186 tensor(2.8546, grad_fn=<NegBackward0>)\n",
      "187 tensor(2.8536, grad_fn=<NegBackward0>)\n",
      "188 tensor(2.8498, grad_fn=<NegBackward0>)\n",
      "189 tensor(2.8489, grad_fn=<NegBackward0>)\n",
      "190 tensor(2.8452, grad_fn=<NegBackward0>)\n",
      "191 tensor(2.8443, grad_fn=<NegBackward0>)\n",
      "192 tensor(2.8407, grad_fn=<NegBackward0>)\n",
      "193 tensor(2.8399, grad_fn=<NegBackward0>)\n",
      "194 tensor(2.8364, grad_fn=<NegBackward0>)\n",
      "195 tensor(2.8356, grad_fn=<NegBackward0>)\n",
      "196 tensor(2.8322, grad_fn=<NegBackward0>)\n",
      "197 tensor(2.8314, grad_fn=<NegBackward0>)\n",
      "198 tensor(2.8281, grad_fn=<NegBackward0>)\n",
      "199 tensor(2.8274, grad_fn=<NegBackward0>)\n",
      "200 tensor(2.8242, grad_fn=<NegBackward0>)\n",
      "201 tensor(2.8235, grad_fn=<NegBackward0>)\n",
      "202 tensor(2.8204, grad_fn=<NegBackward0>)\n",
      "203 tensor(2.8197, grad_fn=<NegBackward0>)\n",
      "204 tensor(2.8167, grad_fn=<NegBackward0>)\n",
      "205 tensor(2.8160, grad_fn=<NegBackward0>)\n",
      "206 tensor(2.8130, grad_fn=<NegBackward0>)\n",
      "207 tensor(2.8124, grad_fn=<NegBackward0>)\n",
      "208 tensor(2.8095, grad_fn=<NegBackward0>)\n",
      "209 tensor(2.8089, grad_fn=<NegBackward0>)\n",
      "210 tensor(2.8061, grad_fn=<NegBackward0>)\n",
      "211 tensor(2.8055, grad_fn=<NegBackward0>)\n",
      "212 tensor(2.8028, grad_fn=<NegBackward0>)\n",
      "213 tensor(2.8022, grad_fn=<NegBackward0>)\n",
      "214 tensor(2.7996, grad_fn=<NegBackward0>)\n",
      "215 tensor(2.7990, grad_fn=<NegBackward0>)\n",
      "216 tensor(2.7964, grad_fn=<NegBackward0>)\n",
      "217 tensor(2.7959, grad_fn=<NegBackward0>)\n",
      "218 tensor(2.7934, grad_fn=<NegBackward0>)\n",
      "219 tensor(2.7929, grad_fn=<NegBackward0>)\n",
      "220 tensor(2.7904, grad_fn=<NegBackward0>)\n",
      "221 tensor(2.7899, grad_fn=<NegBackward0>)\n",
      "222 tensor(2.7874, grad_fn=<NegBackward0>)\n",
      "223 tensor(2.7870, grad_fn=<NegBackward0>)\n",
      "224 tensor(2.7846, grad_fn=<NegBackward0>)\n",
      "225 tensor(2.7842, grad_fn=<NegBackward0>)\n",
      "226 tensor(2.7818, grad_fn=<NegBackward0>)\n",
      "227 tensor(2.7814, grad_fn=<NegBackward0>)\n",
      "228 tensor(2.7791, grad_fn=<NegBackward0>)\n",
      "229 tensor(2.7787, grad_fn=<NegBackward0>)\n",
      "230 tensor(2.7764, grad_fn=<NegBackward0>)\n",
      "231 tensor(2.7761, grad_fn=<NegBackward0>)\n",
      "232 tensor(2.7738, grad_fn=<NegBackward0>)\n",
      "233 tensor(2.7735, grad_fn=<NegBackward0>)\n",
      "234 tensor(2.7712, grad_fn=<NegBackward0>)\n",
      "235 tensor(2.7709, grad_fn=<NegBackward0>)\n",
      "236 tensor(2.7687, grad_fn=<NegBackward0>)\n",
      "237 tensor(2.7685, grad_fn=<NegBackward0>)\n",
      "238 tensor(2.7663, grad_fn=<NegBackward0>)\n",
      "239 tensor(2.7660, grad_fn=<NegBackward0>)\n",
      "240 tensor(2.7639, grad_fn=<NegBackward0>)\n",
      "241 tensor(2.7636, grad_fn=<NegBackward0>)\n",
      "242 tensor(2.7615, grad_fn=<NegBackward0>)\n",
      "243 tensor(2.7613, grad_fn=<NegBackward0>)\n",
      "244 tensor(2.7592, grad_fn=<NegBackward0>)\n",
      "245 tensor(2.7590, grad_fn=<NegBackward0>)\n",
      "246 tensor(2.7569, grad_fn=<NegBackward0>)\n",
      "247 tensor(2.7567, grad_fn=<NegBackward0>)\n",
      "248 tensor(2.7546, grad_fn=<NegBackward0>)\n",
      "249 tensor(2.7545, grad_fn=<NegBackward0>)\n",
      "250 tensor(2.7524, grad_fn=<NegBackward0>)\n",
      "251 tensor(2.7523, grad_fn=<NegBackward0>)\n",
      "252 tensor(2.7502, grad_fn=<NegBackward0>)\n",
      "253 tensor(2.7501, grad_fn=<NegBackward0>)\n",
      "254 tensor(2.7481, grad_fn=<NegBackward0>)\n",
      "255 tensor(2.7480, grad_fn=<NegBackward0>)\n",
      "256 tensor(2.7460, grad_fn=<NegBackward0>)\n",
      "257 tensor(2.7459, grad_fn=<NegBackward0>)\n",
      "258 tensor(2.7439, grad_fn=<NegBackward0>)\n",
      "259 tensor(2.7438, grad_fn=<NegBackward0>)\n",
      "260 tensor(2.7418, grad_fn=<NegBackward0>)\n",
      "261 tensor(2.7417, grad_fn=<NegBackward0>)\n",
      "262 tensor(2.7398, grad_fn=<NegBackward0>)\n",
      "263 tensor(2.7397, grad_fn=<NegBackward0>)\n",
      "264 tensor(2.7378, grad_fn=<NegBackward0>)\n",
      "265 tensor(2.7377, grad_fn=<NegBackward0>)\n",
      "266 tensor(2.7358, grad_fn=<NegBackward0>)\n",
      "267 tensor(2.7357, grad_fn=<NegBackward0>)\n",
      "268 tensor(2.7338, grad_fn=<NegBackward0>)\n",
      "269 tensor(2.7338, grad_fn=<NegBackward0>)\n",
      "270 tensor(2.7318, grad_fn=<NegBackward0>)\n",
      "271 tensor(2.7318, grad_fn=<NegBackward0>)\n",
      "272 tensor(2.7299, grad_fn=<NegBackward0>)\n",
      "273 tensor(2.7299, grad_fn=<NegBackward0>)\n",
      "274 tensor(2.7280, grad_fn=<NegBackward0>)\n",
      "275 tensor(2.7280, grad_fn=<NegBackward0>)\n",
      "276 tensor(2.7261, grad_fn=<NegBackward0>)\n",
      "277 tensor(2.7261, grad_fn=<NegBackward0>)\n",
      "278 tensor(2.7242, grad_fn=<NegBackward0>)\n",
      "279 tensor(2.7242, grad_fn=<NegBackward0>)\n",
      "280 tensor(2.7223, grad_fn=<NegBackward0>)\n",
      "281 tensor(2.7223, grad_fn=<NegBackward0>)\n",
      "282 tensor(2.7204, grad_fn=<NegBackward0>)\n",
      "283 tensor(2.7204, grad_fn=<NegBackward0>)\n",
      "284 tensor(2.7186, grad_fn=<NegBackward0>)\n",
      "285 tensor(2.7186, grad_fn=<NegBackward0>)\n",
      "286 tensor(2.7167, grad_fn=<NegBackward0>)\n",
      "287 tensor(2.7167, grad_fn=<NegBackward0>)\n",
      "288 tensor(2.7149, grad_fn=<NegBackward0>)\n",
      "289 tensor(2.7149, grad_fn=<NegBackward0>)\n",
      "290 tensor(2.7130, grad_fn=<NegBackward0>)\n",
      "291 tensor(2.7131, grad_fn=<NegBackward0>)\n",
      "292 tensor(2.7112, grad_fn=<NegBackward0>)\n",
      "293 tensor(2.7113, grad_fn=<NegBackward0>)\n",
      "294 tensor(2.7094, grad_fn=<NegBackward0>)\n",
      "295 tensor(2.7095, grad_fn=<NegBackward0>)\n",
      "296 tensor(2.7076, grad_fn=<NegBackward0>)\n",
      "297 tensor(2.7077, grad_fn=<NegBackward0>)\n",
      "298 tensor(2.7058, grad_fn=<NegBackward0>)\n",
      "299 tensor(2.7059, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for iter in range(300):\n",
    "\n",
    "  # forward\n",
    "  embeddings = X @ embedding_matrix\n",
    "  embeddings_flattened = embeddings.view(-1, context_window * embedding_vector_dimensionality) # think about traversal order\n",
    "\n",
    "  hidden_layer_preactivations = embeddings_flattened @ hidden_layer_weights + hidden_layer_biases\n",
    "  hidden_layer_activations = hidden_layer_preactivations.tanh()\n",
    "\n",
    "  output_layer_preactivations = hidden_layer_activations @ output_layer_weights + output_layer_biases\n",
    "  output_layer_activations = output_layer_preactivations\n",
    "  logits = output_layer_activations\n",
    "\n",
    "  logits_sub_max = logits - logits.max(dim=1, keepdim=True).values\n",
    "  counts = logits_sub_max.exp()\n",
    "  prob_distributions = counts / counts.sum(dim=1, keepdim=True)\n",
    "\n",
    "  target_probs = prob_distributions[torch.arange(X.shape[0]), y_idx]\n",
    "  target_logprobs = target_probs.log()\n",
    "  negative_average_log_likelihood = -target_logprobs.mean()\n",
    "  loss = negative_average_log_likelihood\n",
    "\n",
    "  losses.append(loss); print(iter, loss)\n",
    "\n",
    "  intermediates = [embeddings, embeddings_flattened, hidden_layer_preactivations, hidden_layer_activations, output_layer_preactivations, output_layer_activations, logits, logits_sub_max, counts, prob_distributions, target_probs, target_logprobs] # new objects created each forward pass, so i think i need to redefine this each time\n",
    "  params_and_intermediates = parameters + intermediates\n",
    "\n",
    "  # backward\n",
    "  for tensor in params_and_intermediates:\n",
    "    tensor.grad = None\n",
    "\n",
    "  learning_rate = 0.1\n",
    "  loss.backward()\n",
    "  embedding_matrix.data = embedding_matrix.data - learning_rate * embedding_matrix.grad\n",
    "  hidden_layer_weights.data = hidden_layer_weights.data - learning_rate * hidden_layer_weights.grad\n",
    "  hidden_layer_biases.data = hidden_layer_biases.data - learning_rate * hidden_layer_biases.grad\n",
    "  output_layer_weights.data = output_layer_weights.data - learning_rate * output_layer_weights.grad\n",
    "  output_layer_biases.data = output_layer_biases.data - learning_rate * output_layer_biases.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
