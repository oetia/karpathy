{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorporating more context into the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = open(\"data/names.txt\").read()\n",
    "names = raw.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(\"\".join(names) + \".\")))\n",
    "char_to_num = { char: num for num, char in enumerate(chars) }\n",
    "num_to_char = { num: char for char, num in char_to_num.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..e\n",
      ".em\n",
      "emm\n",
      "mma\n",
      "ma.\n",
      "..emma.\n"
     ]
    }
   ],
   "source": [
    "context_window = 3\n",
    "for name in names:\n",
    "  name = (\".\" * (context_window - 1)) + name + \".\"\n",
    "  for ngram_end_idx in range(context_window - 1, len(name)):\n",
    "    n_gram = name[ngram_end_idx - 2: ngram_end_idx + 1]\n",
    "    print(n_gram)\n",
    "  print(name)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(5)[[0, 1, 2, 3], [0, 1, 2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3, 27]), torch.Size([228146, 27]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "eye = torch.eye(len(chars))\n",
    "\n",
    "context_window = 3 # doesn't include output i guess.\n",
    "for name in names:\n",
    "  string = \".\" * (context_window) + name + \".\"\n",
    "  string_nums = [char_to_num[char] for char in string]\n",
    "\n",
    "  for idx in range(context_window, len(string)):\n",
    "    substring_nums = string_nums[idx - context_window:idx]\n",
    "    target_num = string_nums[idx]\n",
    "    x = eye[substring_nums]; X.append(x)\n",
    "    y = eye[target_num]; Y.append(y)\n",
    "    \n",
    "    # print(f\"{string[idx - context_window:idx]} -> {string[idx]}\")\n",
    "    # print(f\"{substring_nums} -> {target_num}\")\n",
    "    # print(x, y)\n",
    "\n",
    "X = torch.stack(X) # stack to merge list of tensors\n",
    "Y = torch.stack(Y)\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 27])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have an embedding matrix for the inputs. \n",
    "# for each example, want to pass the 3 27 dimensional vectors via matrix multiplication to pluck out the corresponding 2 dimensional vector. \n",
    "generator = torch.Generator().manual_seed(14)\n",
    "embedding_vector_dimensionality = 2\n",
    "embedding_matrix = torch.randn((len(chars), embedding_vector_dimensionality), generator=generator, requires_grad=True) # all operation results involving this tensor will have gradients tracked. \n",
    "# torch.eye(27)[5].view(1, -1) @ embedding_matrix # [ 1.8372, -1.4072]\n",
    "\n",
    "# forward pass\n",
    "embeddings = X @ embedding_matrix\n",
    "embeddings.shape\n",
    "\n",
    "# c-style indexing. will go from the rightmost dimension, and increment gradually. \n",
    "# view works here. when building out that group of 6, will go 2 + 2 + 2 -> 6. order is intrinsically maintained through position within that group of 6. \n",
    "embedding_layer_size = context_window * embedding_vector_dimensionality\n",
    "merged_embedding = embeddings.view(-1, embedding_layer_size)\n",
    "# merged_embedding.shape\n",
    "\n",
    "# not sure what the size for the hidden layer should be.  \n",
    "hidden_layer_size = 100\n",
    "hidden_weights = torch.randn((embedding_layer_size, hidden_layer_size), generator=generator, requires_grad=True) # dot product to generate output for a node in hidden layer. 6 inputs, 6 weights, for a single output. need to repeat this for each node. (, embed_size) @ (embed_size, hidden_size). matrix multiplication as a conveneint means to perform this computation. \n",
    "hidden_biases = torch.randn((hidden_layer_size), generator=generator, requires_grad=True)\n",
    "\n",
    "hidden_preactivation = merged_embedding @ hidden_weights + hidden_biases\n",
    "hidden_activation = torch.maximum(hidden_preactivation, torch.ones_like(hidden_preactivation)) # maximum() does element-wise max - basically relu relu\n",
    "\n",
    "output_layer_size = len(chars)\n",
    "output_weights = torch.randn((hidden_layer_size, output_layer_size), generator=generator, requires_grad=True) # for a given example, dot product between hidden ouput and output weights for each neuron in output layer.\n",
    "output_biases = torch.randn((output_layer_size), generator=generator, requires_grad=True)\n",
    "\n",
    "output_preactivation = hidden_activation @ output_weights + output_biases\n",
    "output_activation = output_preactivation # no activation function for output layer.\n",
    "logits = output_activation\n",
    "\n",
    "counts = logits.exp()\n",
    "probabilities = counts / counts.sum(dim=1, keepdim=True)\n",
    "\n",
    "# hidden_activation.shape\n",
    "# output_activation.shape\n",
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 6])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not quite what is wanted. \n",
    "# anyhow, the goal this time around is to incorporate more context into the function. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
