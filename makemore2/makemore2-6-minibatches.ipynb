{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = open(\"data/names.txt\").read()\n",
    "names = raw.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(\"\".join(names) + \".\")))\n",
    "char_to_num = { char: num for num, char in enumerate(chars) }\n",
    "num_to_char = { num: char for char, num in char_to_num.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3, 27]), torch.Size([228146, 27]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "Y = []; y_idx = []\n",
    "eye = torch.eye(len(chars))\n",
    "\n",
    "context_window = 3\n",
    "for name in names:\n",
    "  string = \".\" * (context_window) + name + \".\"\n",
    "  string_nums = [char_to_num[char] for char in string]\n",
    "\n",
    "  for idx in range(context_window, len(string)):\n",
    "    substring_nums = string_nums[idx - context_window:idx]\n",
    "    target_num = string_nums[idx]\n",
    "    x = eye[substring_nums]; X.append(x)\n",
    "    y = eye[target_num]; Y.append(y); y_idx.append(target_num)\n",
    "    \n",
    "    # print(f\"{string[idx - context_window:idx]} -> {string[idx]}\")\n",
    "    # print(f\"{substring_nums} -> {target_num}\")\n",
    "    # print(x, y)\n",
    "\n",
    "X = torch.stack(X) # stack to merge list of tensors\n",
    "Y = torch.stack(Y); y_idx = torch.tensor(y_idx)\n",
    "\n",
    "X.shape, Y.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing parameters\n",
    "generator = torch.Generator().manual_seed(14)\n",
    "embedding_vector_dimensionality = 2\n",
    "embedding_matrix = torch.randn((len(chars), embedding_vector_dimensionality), generator=generator, requires_grad=True)\n",
    "\n",
    "hidden_layer_num_neurons = 100\n",
    "hidden_layer_weights = torch.randn((context_window * embedding_vector_dimensionality, hidden_layer_num_neurons), generator=generator, requires_grad=True)\n",
    "hidden_layer_biases = torch.randn((hidden_layer_num_neurons), generator=generator, requires_grad=True)\n",
    "\n",
    "output_layer_num_neurons = len(chars)\n",
    "output_layer_weights = torch.randn((hidden_layer_num_neurons, output_layer_num_neurons), generator=generator, requires_grad=True)\n",
    "output_layer_biases = torch.randn((output_layer_num_neurons), generator=generator, requires_grad=True)\n",
    "\n",
    "parameters = [embedding_matrix, hidden_layer_weights, hidden_layer_biases, output_layer_weights, output_layer_biases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228146, 3, 2])\n",
      "torch.Size([228146, 6])\n",
      "torch.Size([228146, 100])\n",
      "torch.Size([228146, 27])\n",
      "torch.Size([228146, 27]) tensor(True)\n",
      "torch.Size([228146])\n",
      "tensor(18.3288, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "embeddings = X @ embedding_matrix\n",
    "print(embeddings.shape)\n",
    "\n",
    "embeddings_flattened = embeddings.view(-1, context_window * embedding_vector_dimensionality) # think about traversal order\n",
    "print(embeddings_flattened.shape)\n",
    "\n",
    "hidden_layer_preactivations = embeddings_flattened @ hidden_layer_weights + hidden_layer_biases\n",
    "# hidden_layer_activations = torch.maximum(hidden_layer_preactivations, torch.tensor(0.0))\n",
    "hidden_layer_activations = hidden_layer_preactivations.tanh()\n",
    "print(hidden_layer_activations.shape)\n",
    "\n",
    "output_layer_preactivations = hidden_layer_activations @ output_layer_weights + output_layer_biases\n",
    "output_layer_activations = output_layer_preactivations\n",
    "logits = output_layer_activations\n",
    "print(logits.shape)\n",
    "\n",
    "logits_sub_max = logits - logits.max(dim=1, keepdim=True).values\n",
    "counts = logits_sub_max.exp()\n",
    "prob_distributions = counts / counts.sum(dim=1, keepdim=True)\n",
    "print(prob_distributions.shape, prob_distributions.sum(dim=1).isclose(torch.tensor(1.0)).all())\n",
    "\n",
    "target_probs = prob_distributions[torch.arange(X.shape[0]), y_idx]\n",
    "target_logprobs = target_probs.log()\n",
    "print(target_logprobs.shape)\n",
    "\n",
    "negative_average_log_likelihood = -target_logprobs.mean()\n",
    "loss = negative_average_log_likelihood\n",
    "print(loss)\n",
    "\n",
    "intermediates = [embeddings, embeddings_flattened, hidden_layer_preactivations, hidden_layer_activations, output_layer_preactivations, output_layer_activations, logits, logits_sub_max, counts, prob_distributions, target_probs, target_logprobs]\n",
    "params_and_intermediates = parameters + intermediates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "for tensor in params_and_intermediates:\n",
    "  tensor.grad = None\n",
    "\n",
    "learning_rate = 0.01\n",
    "loss.backward()\n",
    "embedding_matrix.data = embedding_matrix.data - learning_rate * embedding_matrix.grad\n",
    "hidden_layer_weights.data = hidden_layer_weights.data - learning_rate * hidden_layer_weights.grad\n",
    "hidden_layer_biases.data = hidden_layer_biases.data - learning_rate * hidden_layer_biases.grad\n",
    "output_layer_weights.data = output_layer_weights.data - learning_rate * output_layer_weights.grad\n",
    "output_layer_biases.data = output_layer_biases.data - learning_rate * output_layer_biases.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computation graph gets nuked after backward() called. don't need to worry about duplicate nodes getting created each forward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(5.4100, grad_fn=<NegBackward0>)\n",
      "1 tensor(7.2942, grad_fn=<NegBackward0>)\n",
      "2 tensor(5.6942, grad_fn=<NegBackward0>)\n",
      "3 tensor(6.1556, grad_fn=<NegBackward0>)\n",
      "4 tensor(7.1429, grad_fn=<NegBackward0>)\n",
      "5 tensor(6.5570, grad_fn=<NegBackward0>)\n",
      "6 tensor(5.3955, grad_fn=<NegBackward0>)\n",
      "7 tensor(6.8647, grad_fn=<NegBackward0>)\n",
      "8 tensor(7.9991, grad_fn=<NegBackward0>)\n",
      "9 tensor(9.2423, grad_fn=<NegBackward0>)\n",
      "10 tensor(7.1994, grad_fn=<NegBackward0>)\n",
      "11 tensor(7.6093, grad_fn=<NegBackward0>)\n",
      "12 tensor(7.6319, grad_fn=<NegBackward0>)\n",
      "13 tensor(7.3892, grad_fn=<NegBackward0>)\n",
      "14 tensor(7.6806, grad_fn=<NegBackward0>)\n",
      "15 tensor(5.9822, grad_fn=<NegBackward0>)\n",
      "16 tensor(8.3052, grad_fn=<NegBackward0>)\n",
      "17 tensor(6.7633, grad_fn=<NegBackward0>)\n",
      "18 tensor(6.7807, grad_fn=<NegBackward0>)\n",
      "19 tensor(6.3138, grad_fn=<NegBackward0>)\n",
      "20 tensor(6.7246, grad_fn=<NegBackward0>)\n",
      "21 tensor(5.1100, grad_fn=<NegBackward0>)\n",
      "22 tensor(6.3274, grad_fn=<NegBackward0>)\n",
      "23 tensor(6.5055, grad_fn=<NegBackward0>)\n",
      "24 tensor(5.1109, grad_fn=<NegBackward0>)\n",
      "25 tensor(8.0091, grad_fn=<NegBackward0>)\n",
      "26 tensor(8.9235, grad_fn=<NegBackward0>)\n",
      "27 tensor(8.9176, grad_fn=<NegBackward0>)\n",
      "28 tensor(7.8663, grad_fn=<NegBackward0>)\n",
      "29 tensor(8.6545, grad_fn=<NegBackward0>)\n",
      "30 tensor(7.1836, grad_fn=<NegBackward0>)\n",
      "31 tensor(6.8826, grad_fn=<NegBackward0>)\n",
      "32 tensor(6.8607, grad_fn=<NegBackward0>)\n",
      "33 tensor(7.6149, grad_fn=<NegBackward0>)\n",
      "34 tensor(8.3240, grad_fn=<NegBackward0>)\n",
      "35 tensor(6.9114, grad_fn=<NegBackward0>)\n",
      "36 tensor(6.3168, grad_fn=<NegBackward0>)\n",
      "37 tensor(9.3838, grad_fn=<NegBackward0>)\n",
      "38 tensor(6.0877, grad_fn=<NegBackward0>)\n",
      "39 tensor(6.5090, grad_fn=<NegBackward0>)\n",
      "40 tensor(5.9359, grad_fn=<NegBackward0>)\n",
      "41 tensor(7.6845, grad_fn=<NegBackward0>)\n",
      "42 tensor(5.3919, grad_fn=<NegBackward0>)\n",
      "43 tensor(8.6858, grad_fn=<NegBackward0>)\n",
      "44 tensor(7.3954, grad_fn=<NegBackward0>)\n",
      "45 tensor(6.9135, grad_fn=<NegBackward0>)\n",
      "46 tensor(5.4879, grad_fn=<NegBackward0>)\n",
      "47 tensor(5.8257, grad_fn=<NegBackward0>)\n",
      "48 tensor(5.5357, grad_fn=<NegBackward0>)\n",
      "49 tensor(7.0277, grad_fn=<NegBackward0>)\n",
      "50 tensor(7.9132, grad_fn=<NegBackward0>)\n",
      "51 tensor(7.0674, grad_fn=<NegBackward0>)\n",
      "52 tensor(5.1976, grad_fn=<NegBackward0>)\n",
      "53 tensor(7.5136, grad_fn=<NegBackward0>)\n",
      "54 tensor(6.4310, grad_fn=<NegBackward0>)\n",
      "55 tensor(6.4094, grad_fn=<NegBackward0>)\n",
      "56 tensor(6.1975, grad_fn=<NegBackward0>)\n",
      "57 tensor(6.2234, grad_fn=<NegBackward0>)\n",
      "58 tensor(8.9573, grad_fn=<NegBackward0>)\n",
      "59 tensor(5.8993, grad_fn=<NegBackward0>)\n",
      "60 tensor(6.0505, grad_fn=<NegBackward0>)\n",
      "61 tensor(6.5040, grad_fn=<NegBackward0>)\n",
      "62 tensor(5.8263, grad_fn=<NegBackward0>)\n",
      "63 tensor(7.5567, grad_fn=<NegBackward0>)\n",
      "64 tensor(7.3256, grad_fn=<NegBackward0>)\n",
      "65 tensor(8.6863, grad_fn=<NegBackward0>)\n",
      "66 tensor(5.9818, grad_fn=<NegBackward0>)\n",
      "67 tensor(6.2814, grad_fn=<NegBackward0>)\n",
      "68 tensor(6.6096, grad_fn=<NegBackward0>)\n",
      "69 tensor(8.0850, grad_fn=<NegBackward0>)\n",
      "70 tensor(6.3001, grad_fn=<NegBackward0>)\n",
      "71 tensor(6.4707, grad_fn=<NegBackward0>)\n",
      "72 tensor(6.6252, grad_fn=<NegBackward0>)\n",
      "73 tensor(5.1306, grad_fn=<NegBackward0>)\n",
      "74 tensor(5.4957, grad_fn=<NegBackward0>)\n",
      "75 tensor(5.3200, grad_fn=<NegBackward0>)\n",
      "76 tensor(6.2704, grad_fn=<NegBackward0>)\n",
      "77 tensor(7.1384, grad_fn=<NegBackward0>)\n",
      "78 tensor(7.1638, grad_fn=<NegBackward0>)\n",
      "79 tensor(6.2460, grad_fn=<NegBackward0>)\n",
      "80 tensor(6.9844, grad_fn=<NegBackward0>)\n",
      "81 tensor(6.2031, grad_fn=<NegBackward0>)\n",
      "82 tensor(7.4488, grad_fn=<NegBackward0>)\n",
      "83 tensor(5.2478, grad_fn=<NegBackward0>)\n",
      "84 tensor(8.4014, grad_fn=<NegBackward0>)\n",
      "85 tensor(7.8515, grad_fn=<NegBackward0>)\n",
      "86 tensor(6.7892, grad_fn=<NegBackward0>)\n",
      "87 tensor(6.1445, grad_fn=<NegBackward0>)\n",
      "88 tensor(7.0354, grad_fn=<NegBackward0>)\n",
      "89 tensor(6.3248, grad_fn=<NegBackward0>)\n",
      "90 tensor(6.2644, grad_fn=<NegBackward0>)\n",
      "91 tensor(6.5105, grad_fn=<NegBackward0>)\n",
      "92 tensor(8.6078, grad_fn=<NegBackward0>)\n",
      "93 tensor(7.7855, grad_fn=<NegBackward0>)\n",
      "94 tensor(5.7998, grad_fn=<NegBackward0>)\n",
      "95 tensor(6.7176, grad_fn=<NegBackward0>)\n",
      "96 tensor(6.6936, grad_fn=<NegBackward0>)\n",
      "97 tensor(7.2212, grad_fn=<NegBackward0>)\n",
      "98 tensor(6.5937, grad_fn=<NegBackward0>)\n",
      "99 tensor(7.9835, grad_fn=<NegBackward0>)\n",
      "100 tensor(7.6356, grad_fn=<NegBackward0>)\n",
      "101 tensor(6.0805, grad_fn=<NegBackward0>)\n",
      "102 tensor(6.4479, grad_fn=<NegBackward0>)\n",
      "103 tensor(5.9750, grad_fn=<NegBackward0>)\n",
      "104 tensor(6.5450, grad_fn=<NegBackward0>)\n",
      "105 tensor(7.2973, grad_fn=<NegBackward0>)\n",
      "106 tensor(8.0487, grad_fn=<NegBackward0>)\n",
      "107 tensor(5.3819, grad_fn=<NegBackward0>)\n",
      "108 tensor(5.1377, grad_fn=<NegBackward0>)\n",
      "109 tensor(6.5687, grad_fn=<NegBackward0>)\n",
      "110 tensor(6.4614, grad_fn=<NegBackward0>)\n",
      "111 tensor(4.6501, grad_fn=<NegBackward0>)\n",
      "112 tensor(7.6784, grad_fn=<NegBackward0>)\n",
      "113 tensor(7.9962, grad_fn=<NegBackward0>)\n",
      "114 tensor(7.0783, grad_fn=<NegBackward0>)\n",
      "115 tensor(7.2241, grad_fn=<NegBackward0>)\n",
      "116 tensor(6.9499, grad_fn=<NegBackward0>)\n",
      "117 tensor(7.1526, grad_fn=<NegBackward0>)\n",
      "118 tensor(7.4279, grad_fn=<NegBackward0>)\n",
      "119 tensor(6.7463, grad_fn=<NegBackward0>)\n",
      "120 tensor(7.1588, grad_fn=<NegBackward0>)\n",
      "121 tensor(6.3911, grad_fn=<NegBackward0>)\n",
      "122 tensor(7.4641, grad_fn=<NegBackward0>)\n",
      "123 tensor(5.9417, grad_fn=<NegBackward0>)\n",
      "124 tensor(6.0864, grad_fn=<NegBackward0>)\n",
      "125 tensor(6.0525, grad_fn=<NegBackward0>)\n",
      "126 tensor(5.5977, grad_fn=<NegBackward0>)\n",
      "127 tensor(6.4541, grad_fn=<NegBackward0>)\n",
      "128 tensor(4.9929, grad_fn=<NegBackward0>)\n",
      "129 tensor(5.3171, grad_fn=<NegBackward0>)\n",
      "130 tensor(6.2586, grad_fn=<NegBackward0>)\n",
      "131 tensor(7.0080, grad_fn=<NegBackward0>)\n",
      "132 tensor(7.7270, grad_fn=<NegBackward0>)\n",
      "133 tensor(6.0130, grad_fn=<NegBackward0>)\n",
      "134 tensor(7.7802, grad_fn=<NegBackward0>)\n",
      "135 tensor(8.6341, grad_fn=<NegBackward0>)\n",
      "136 tensor(6.9915, grad_fn=<NegBackward0>)\n",
      "137 tensor(6.8840, grad_fn=<NegBackward0>)\n",
      "138 tensor(9.0001, grad_fn=<NegBackward0>)\n",
      "139 tensor(6.8744, grad_fn=<NegBackward0>)\n",
      "140 tensor(6.4038, grad_fn=<NegBackward0>)\n",
      "141 tensor(6.2459, grad_fn=<NegBackward0>)\n",
      "142 tensor(7.4732, grad_fn=<NegBackward0>)\n",
      "143 tensor(7.8566, grad_fn=<NegBackward0>)\n",
      "144 tensor(6.6668, grad_fn=<NegBackward0>)\n",
      "145 tensor(6.8072, grad_fn=<NegBackward0>)\n",
      "146 tensor(7.2707, grad_fn=<NegBackward0>)\n",
      "147 tensor(6.4140, grad_fn=<NegBackward0>)\n",
      "148 tensor(6.8287, grad_fn=<NegBackward0>)\n",
      "149 tensor(5.1084, grad_fn=<NegBackward0>)\n",
      "150 tensor(8.0303, grad_fn=<NegBackward0>)\n",
      "151 tensor(7.7296, grad_fn=<NegBackward0>)\n",
      "152 tensor(7.9456, grad_fn=<NegBackward0>)\n",
      "153 tensor(5.4310, grad_fn=<NegBackward0>)\n",
      "154 tensor(6.2362, grad_fn=<NegBackward0>)\n",
      "155 tensor(7.7481, grad_fn=<NegBackward0>)\n",
      "156 tensor(7.0226, grad_fn=<NegBackward0>)\n",
      "157 tensor(8.3686, grad_fn=<NegBackward0>)\n",
      "158 tensor(6.0040, grad_fn=<NegBackward0>)\n",
      "159 tensor(6.3907, grad_fn=<NegBackward0>)\n",
      "160 tensor(7.8748, grad_fn=<NegBackward0>)\n",
      "161 tensor(6.1305, grad_fn=<NegBackward0>)\n",
      "162 tensor(7.2190, grad_fn=<NegBackward0>)\n",
      "163 tensor(7.3360, grad_fn=<NegBackward0>)\n",
      "164 tensor(7.9287, grad_fn=<NegBackward0>)\n",
      "165 tensor(9.2903, grad_fn=<NegBackward0>)\n",
      "166 tensor(6.3448, grad_fn=<NegBackward0>)\n",
      "167 tensor(7.3608, grad_fn=<NegBackward0>)\n",
      "168 tensor(6.7962, grad_fn=<NegBackward0>)\n",
      "169 tensor(7.9328, grad_fn=<NegBackward0>)\n",
      "170 tensor(6.3116, grad_fn=<NegBackward0>)\n",
      "171 tensor(6.5839, grad_fn=<NegBackward0>)\n",
      "172 tensor(4.9294, grad_fn=<NegBackward0>)\n",
      "173 tensor(6.7664, grad_fn=<NegBackward0>)\n",
      "174 tensor(6.5219, grad_fn=<NegBackward0>)\n",
      "175 tensor(6.8374, grad_fn=<NegBackward0>)\n",
      "176 tensor(5.7197, grad_fn=<NegBackward0>)\n",
      "177 tensor(8.4991, grad_fn=<NegBackward0>)\n",
      "178 tensor(7.4889, grad_fn=<NegBackward0>)\n",
      "179 tensor(5.8491, grad_fn=<NegBackward0>)\n",
      "180 tensor(7.7248, grad_fn=<NegBackward0>)\n",
      "181 tensor(4.1943, grad_fn=<NegBackward0>)\n",
      "182 tensor(6.4164, grad_fn=<NegBackward0>)\n",
      "183 tensor(6.2414, grad_fn=<NegBackward0>)\n",
      "184 tensor(5.9203, grad_fn=<NegBackward0>)\n",
      "185 tensor(7.0935, grad_fn=<NegBackward0>)\n",
      "186 tensor(6.5314, grad_fn=<NegBackward0>)\n",
      "187 tensor(7.5874, grad_fn=<NegBackward0>)\n",
      "188 tensor(5.3375, grad_fn=<NegBackward0>)\n",
      "189 tensor(7.0730, grad_fn=<NegBackward0>)\n",
      "190 tensor(5.6217, grad_fn=<NegBackward0>)\n",
      "191 tensor(8.1649, grad_fn=<NegBackward0>)\n",
      "192 tensor(5.7650, grad_fn=<NegBackward0>)\n",
      "193 tensor(7.6749, grad_fn=<NegBackward0>)\n",
      "194 tensor(6.2998, grad_fn=<NegBackward0>)\n",
      "195 tensor(7.1873, grad_fn=<NegBackward0>)\n",
      "196 tensor(4.2599, grad_fn=<NegBackward0>)\n",
      "197 tensor(6.8543, grad_fn=<NegBackward0>)\n",
      "198 tensor(6.8428, grad_fn=<NegBackward0>)\n",
      "199 tensor(5.7992, grad_fn=<NegBackward0>)\n",
      "200 tensor(6.0354, grad_fn=<NegBackward0>)\n",
      "201 tensor(6.0672, grad_fn=<NegBackward0>)\n",
      "202 tensor(6.8071, grad_fn=<NegBackward0>)\n",
      "203 tensor(6.7396, grad_fn=<NegBackward0>)\n",
      "204 tensor(7.1508, grad_fn=<NegBackward0>)\n",
      "205 tensor(6.7505, grad_fn=<NegBackward0>)\n",
      "206 tensor(7.3434, grad_fn=<NegBackward0>)\n",
      "207 tensor(6.6766, grad_fn=<NegBackward0>)\n",
      "208 tensor(7.5332, grad_fn=<NegBackward0>)\n",
      "209 tensor(4.7568, grad_fn=<NegBackward0>)\n",
      "210 tensor(7.3345, grad_fn=<NegBackward0>)\n",
      "211 tensor(5.7929, grad_fn=<NegBackward0>)\n",
      "212 tensor(6.4116, grad_fn=<NegBackward0>)\n",
      "213 tensor(5.4191, grad_fn=<NegBackward0>)\n",
      "214 tensor(5.2661, grad_fn=<NegBackward0>)\n",
      "215 tensor(6.4122, grad_fn=<NegBackward0>)\n",
      "216 tensor(6.8618, grad_fn=<NegBackward0>)\n",
      "217 tensor(7.8059, grad_fn=<NegBackward0>)\n",
      "218 tensor(7.7522, grad_fn=<NegBackward0>)\n",
      "219 tensor(6.6764, grad_fn=<NegBackward0>)\n",
      "220 tensor(6.8684, grad_fn=<NegBackward0>)\n",
      "221 tensor(6.0257, grad_fn=<NegBackward0>)\n",
      "222 tensor(5.8762, grad_fn=<NegBackward0>)\n",
      "223 tensor(5.2973, grad_fn=<NegBackward0>)\n",
      "224 tensor(5.8417, grad_fn=<NegBackward0>)\n",
      "225 tensor(5.8946, grad_fn=<NegBackward0>)\n",
      "226 tensor(5.1410, grad_fn=<NegBackward0>)\n",
      "227 tensor(7.6918, grad_fn=<NegBackward0>)\n",
      "228 tensor(5.5867, grad_fn=<NegBackward0>)\n",
      "229 tensor(6.9850, grad_fn=<NegBackward0>)\n",
      "230 tensor(7.7880, grad_fn=<NegBackward0>)\n",
      "231 tensor(5.7548, grad_fn=<NegBackward0>)\n",
      "232 tensor(4.6714, grad_fn=<NegBackward0>)\n",
      "233 tensor(4.5731, grad_fn=<NegBackward0>)\n",
      "234 tensor(5.7497, grad_fn=<NegBackward0>)\n",
      "235 tensor(4.8369, grad_fn=<NegBackward0>)\n",
      "236 tensor(6.9292, grad_fn=<NegBackward0>)\n",
      "237 tensor(8.9520, grad_fn=<NegBackward0>)\n",
      "238 tensor(5.0415, grad_fn=<NegBackward0>)\n",
      "239 tensor(7.6123, grad_fn=<NegBackward0>)\n",
      "240 tensor(6.3753, grad_fn=<NegBackward0>)\n",
      "241 tensor(7.3714, grad_fn=<NegBackward0>)\n",
      "242 tensor(6.0681, grad_fn=<NegBackward0>)\n",
      "243 tensor(6.2246, grad_fn=<NegBackward0>)\n",
      "244 tensor(6.4133, grad_fn=<NegBackward0>)\n",
      "245 tensor(5.9787, grad_fn=<NegBackward0>)\n",
      "246 tensor(7.0304, grad_fn=<NegBackward0>)\n",
      "247 tensor(6.7978, grad_fn=<NegBackward0>)\n",
      "248 tensor(6.4710, grad_fn=<NegBackward0>)\n",
      "249 tensor(5.1162, grad_fn=<NegBackward0>)\n",
      "250 tensor(8.2859, grad_fn=<NegBackward0>)\n",
      "251 tensor(7.4841, grad_fn=<NegBackward0>)\n",
      "252 tensor(6.6749, grad_fn=<NegBackward0>)\n",
      "253 tensor(7.2584, grad_fn=<NegBackward0>)\n",
      "254 tensor(5.6434, grad_fn=<NegBackward0>)\n",
      "255 tensor(7.4567, grad_fn=<NegBackward0>)\n",
      "256 tensor(5.4154, grad_fn=<NegBackward0>)\n",
      "257 tensor(7.0183, grad_fn=<NegBackward0>)\n",
      "258 tensor(6.6104, grad_fn=<NegBackward0>)\n",
      "259 tensor(5.5637, grad_fn=<NegBackward0>)\n",
      "260 tensor(6.1717, grad_fn=<NegBackward0>)\n",
      "261 tensor(4.1757, grad_fn=<NegBackward0>)\n",
      "262 tensor(6.2478, grad_fn=<NegBackward0>)\n",
      "263 tensor(5.6619, grad_fn=<NegBackward0>)\n",
      "264 tensor(5.2188, grad_fn=<NegBackward0>)\n",
      "265 tensor(7.1933, grad_fn=<NegBackward0>)\n",
      "266 tensor(6.5217, grad_fn=<NegBackward0>)\n",
      "267 tensor(8.6806, grad_fn=<NegBackward0>)\n",
      "268 tensor(6.9513, grad_fn=<NegBackward0>)\n",
      "269 tensor(5.1431, grad_fn=<NegBackward0>)\n",
      "270 tensor(7.4634, grad_fn=<NegBackward0>)\n",
      "271 tensor(6.1520, grad_fn=<NegBackward0>)\n",
      "272 tensor(6.5756, grad_fn=<NegBackward0>)\n",
      "273 tensor(5.4304, grad_fn=<NegBackward0>)\n",
      "274 tensor(6.1966, grad_fn=<NegBackward0>)\n",
      "275 tensor(6.4706, grad_fn=<NegBackward0>)\n",
      "276 tensor(5.4975, grad_fn=<NegBackward0>)\n",
      "277 tensor(6.1642, grad_fn=<NegBackward0>)\n",
      "278 tensor(5.9354, grad_fn=<NegBackward0>)\n",
      "279 tensor(7.2506, grad_fn=<NegBackward0>)\n",
      "280 tensor(5.5531, grad_fn=<NegBackward0>)\n",
      "281 tensor(7.3817, grad_fn=<NegBackward0>)\n",
      "282 tensor(6.0641, grad_fn=<NegBackward0>)\n",
      "283 tensor(5.7651, grad_fn=<NegBackward0>)\n",
      "284 tensor(6.6094, grad_fn=<NegBackward0>)\n",
      "285 tensor(6.6681, grad_fn=<NegBackward0>)\n",
      "286 tensor(6.4508, grad_fn=<NegBackward0>)\n",
      "287 tensor(9.0379, grad_fn=<NegBackward0>)\n",
      "288 tensor(6.5451, grad_fn=<NegBackward0>)\n",
      "289 tensor(7.0623, grad_fn=<NegBackward0>)\n",
      "290 tensor(7.0678, grad_fn=<NegBackward0>)\n",
      "291 tensor(6.1471, grad_fn=<NegBackward0>)\n",
      "292 tensor(7.2884, grad_fn=<NegBackward0>)\n",
      "293 tensor(7.9085, grad_fn=<NegBackward0>)\n",
      "294 tensor(6.4800, grad_fn=<NegBackward0>)\n",
      "295 tensor(5.9366, grad_fn=<NegBackward0>)\n",
      "296 tensor(6.2459, grad_fn=<NegBackward0>)\n",
      "297 tensor(6.9963, grad_fn=<NegBackward0>)\n",
      "298 tensor(6.5595, grad_fn=<NegBackward0>)\n",
      "299 tensor(6.8922, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for iter in range(300):\n",
    "\n",
    "  # minibatching\n",
    "  minibatch_idxs = torch.randint(0, X.shape[0], (32,))\n",
    "  X_mini = X[minibatch_idxs]\n",
    "  y_idx_mini = y_idx[minibatch_idxs]\n",
    "\n",
    "  # forward\n",
    "  embeddings = X_mini @ embedding_matrix\n",
    "  embeddings_flattened = embeddings.view(-1, context_window * embedding_vector_dimensionality) # think about traversal order\n",
    "\n",
    "  hidden_layer_preactivations = embeddings_flattened @ hidden_layer_weights + hidden_layer_biases\n",
    "  hidden_layer_activations = hidden_layer_preactivations.tanh()\n",
    "\n",
    "  output_layer_preactivations = hidden_layer_activations @ output_layer_weights + output_layer_biases\n",
    "  output_layer_activations = output_layer_preactivations\n",
    "  logits = output_layer_activations\n",
    "\n",
    "  logits_sub_max = logits - logits.max(dim=1, keepdim=True).values\n",
    "  counts = logits_sub_max.exp()\n",
    "  prob_distributions = counts / counts.sum(dim=1, keepdim=True)\n",
    "\n",
    "  target_probs = prob_distributions[torch.arange(X_mini.shape[0]), y_idx_mini]\n",
    "  target_logprobs = target_probs.log()\n",
    "  negative_average_log_likelihood = -target_logprobs.mean()\n",
    "  loss = negative_average_log_likelihood\n",
    "\n",
    "  losses.append(loss); print(iter, loss)\n",
    "\n",
    "  intermediates = [embeddings, embeddings_flattened, hidden_layer_preactivations, hidden_layer_activations, output_layer_preactivations, output_layer_activations, logits, logits_sub_max, counts, prob_distributions, target_probs, target_logprobs] # new objects created each forward pass, so i think i need to redefine this each time\n",
    "  params_and_intermediates = parameters + intermediates\n",
    "\n",
    "  # backward\n",
    "  for tensor in params_and_intermediates:\n",
    "    tensor.grad = None\n",
    "\n",
    "  learning_rate = 0.01\n",
    "  loss.backward()\n",
    "  embedding_matrix.data = embedding_matrix.data - learning_rate * embedding_matrix.grad\n",
    "  hidden_layer_weights.data = hidden_layer_weights.data - learning_rate * hidden_layer_weights.grad\n",
    "  hidden_layer_biases.data = hidden_layer_biases.data - learning_rate * hidden_layer_biases.grad\n",
    "  output_layer_weights.data = output_layer_weights.data - learning_rate * output_layer_weights.grad\n",
    "  output_layer_biases.data = output_layer_biases.data - learning_rate * output_layer_biases.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
