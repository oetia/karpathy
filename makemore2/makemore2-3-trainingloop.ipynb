{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = open(\"data/names.txt\").read()\n",
    "names = raw.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(\"\".join(names) + \".\")))\n",
    "char_to_num = { char: num for num, char in enumerate(chars) }\n",
    "num_to_char = { num: char for char, num in char_to_num.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 2, 27]), torch.Size([228146, 27]), torch.Size([228146]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "Y = []; y_idx = []\n",
    "eye = torch.eye(len(chars))\n",
    "\n",
    "context_window = 2\n",
    "for name in names:\n",
    "  string = \".\" * (context_window) + name + \".\"\n",
    "  string_nums = [char_to_num[char] for char in string]\n",
    "\n",
    "  for idx in range(context_window, len(string)):\n",
    "    substring_nums = string_nums[idx - context_window:idx]\n",
    "    target_num = string_nums[idx]\n",
    "    x = eye[substring_nums]; X.append(x)\n",
    "    y = eye[target_num]; Y.append(y); y_idx.append(target_num)\n",
    "    \n",
    "    # print(f\"{string[idx - context_window:idx]} -> {string[idx]}\")\n",
    "    # print(f\"{substring_nums} -> {target_num}\")\n",
    "    # print(x, y)\n",
    "\n",
    "X = torch.stack(X) # stack to merge list of tensors\n",
    "Y = torch.stack(Y); y_idx = torch.tensor(y_idx)\n",
    "\n",
    "X.shape, Y.shape, y_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing parameters\n",
    "generator = torch.Generator().manual_seed(14)\n",
    "embedding_vector_dimensionality = 2\n",
    "embedding_matrix = torch.randn((len(chars), embedding_vector_dimensionality), generator=generator, requires_grad=True)\n",
    "\n",
    "hidden_layer_num_neurons = 100\n",
    "hidden_layer_weights = torch.randn((context_window * embedding_vector_dimensionality, hidden_layer_num_neurons), generator=generator, requires_grad=True)\n",
    "hidden_layer_biases = torch.randn((hidden_layer_num_neurons), generator=generator, requires_grad=True)\n",
    "\n",
    "output_layer_num_neurons = len(chars)\n",
    "output_layer_weights = torch.randn((hidden_layer_num_neurons, output_layer_num_neurons), generator=generator, requires_grad=True)\n",
    "output_layer_biases = torch.randn((output_layer_num_neurons), generator=generator, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228146, 2, 2])\n",
      "torch.Size([228146, 4])\n",
      "torch.Size([228146, 100])\n",
      "torch.Size([228146, 27])\n",
      "torch.Size([228146, 27]) tensor(True)\n",
      "torch.Size([228146])\n",
      "tensor(15.7477, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "embeddings = X @ embedding_matrix\n",
    "print(embeddings.shape)\n",
    "\n",
    "embeddings_flattened = embeddings.view(-1, context_window * embedding_vector_dimensionality) # think about traversal order\n",
    "print(embeddings_flattened.shape)\n",
    "\n",
    "hidden_layer_preactivations = embeddings_flattened @ hidden_layer_weights + hidden_layer_biases\n",
    "# hidden_layer_activations = torch.maximum(hidden_layer_preactivations, torch.tensor(0.0))\n",
    "hidden_layer_activations = hidden_layer_preactivations.tanh()\n",
    "print(hidden_layer_activations.shape)\n",
    "\n",
    "output_layer_preactivations = hidden_layer_activations @ output_layer_weights + output_layer_biases\n",
    "output_layer_activations = output_layer_preactivations\n",
    "logits = output_layer_activations\n",
    "print(logits.shape)\n",
    "\n",
    "logits_sub_max = logits - logits.max(dim=1, keepdim=True).values\n",
    "counts = logits_sub_max.exp()\n",
    "prob_distributions = counts / counts.sum(dim=1, keepdim=True)\n",
    "print(prob_distributions.shape, prob_distributions.sum(dim=1).isclose(torch.tensor(1.0)).all())\n",
    "\n",
    "target_probs = prob_distributions[torch.arange(X.shape[0]), y_idx]\n",
    "target_logprobs = target_probs.log()\n",
    "print(target_logprobs.shape)\n",
    "\n",
    "negative_average_log_likelihood = -target_logprobs.mean()\n",
    "loss = negative_average_log_likelihood\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
